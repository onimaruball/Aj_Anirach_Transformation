{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "adc13926",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example of data in this task\n",
    "data = pd.read_excel(r'C:\\Users\\ASUS\\Downloads\\all_data_filtered_ver2.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "28efbad1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'การจัดการทางสังคม\\nประเวศ วะสี\\n๕ พฤศจิกายน ๒๕๖๕\\nนิสิตปริญญาเอก ปรัชญาดุษฎีบัณฑิต การจัดการทางสังคม คณะสังคมศาสตร์\\nสังคม = การอยู่ร่วมกัน\\n= สิ่งสูงสุดของมนุษยชาติ\\nต้องเป็ นตัวตั้งของการพัฒนา\\nการอยู่ร่วมกันอย่างเป็ นธรรม\\n= การอยู่ร่วมกันอย่างสมดุล\\nสมดุล  สงบสุข  ปรกติ  สุขภาวะ  สันติ\\nในประวัติศาสตร์โดยเฉพาะจีน\\nราษฎรไม่เคยได้รับความเป็ นธรรม\\nขูดรีดภาษี ยากจน\\nเกณฑ์ไปใช้แรงงาน\\nเกณฑ์ไปตายในสงคราม\\nต่อสู้อย่างไร ๆ ก็ไม่สําเร็จ\\nกฏทางฟิสิกส์\\nอะไรที่มีมวลมากมีแรงดึงดูดเข้าหาตัวเองมาก\\nมวลอํานาจในสังคม ดึงดูดทรัพยากรเข้าหาตัว\\n= ความไม่เป็ นธรรม\\nมวลอํานาจรัฐ \\n= รัฏฐานุภาพ\\nมวลอํานาจเงิน\\n= ธนานุภาพ\\nมวลอํานาจสังคม = สังคมานุภาพ\\nการกระจายทรัพยากรไม่สมดุล\\n(ก) มวลอํานาจไม่สมดุล\\nรัฐ\\nเงิน\\nสังคม\\nการกระจายทรัพยากรสมดุล\\n(ข) มวลอํานาจสมดุล\\n= ความเป็ นธรรม\\nสังคม\\nเงิน\\nรัฐ\\n“สังคมเข้มแข็ง”\\nการจัดการ = เครื่องมือสร้างสังคมเข้มแข็ง\\nสังคมที่มีความเป็ นธรรมซึ่งเป็ นเรื่องสําคัญที่สุด\\nการจัดการ   = อิทธิปัญญา\\n(อิทธิ = สําเร็จ)\\nเป็ นปัญญาเชิงระบบ\\nประเทศไทยขาดสมรรถนะในการคิดเชิงระบบและการจัดการ\\nคิดว่าดีชั่วเป็ นกรรมส่วนบุคคล\\nและคิดเชิงเทคนิคเท่านั้น\\n“องค์รวม”   คุณสมบัติใหม่อันมหัศจรรย์\\nวัตถุประสงค์\\nการออกแบบระบบและโครงสร้าง\\nองค์กรที่มีพลังสร้างสรรค์และความสุข\\nองค์กร ล้วนมีความทุกข์\\nDee Hock - “Birth of the Chaordic Age”\\nRobert Chamber - ทําไมการพัฒนาในโลกไม่ประสบความสําเร็จ\\nTurid Sato – โครงการใน World Bank 5,000 โครงการ\\nBill Smith – AIC\\nAIC\\nI. จินตนาการสิ่งที่ดีที่สุดขององค์กร =  Policy\\nII. จะต้องทําเรื่องใหญ่ ๆ อะไรบ้าง  = Strategies\\nIII. ทํา Plan of action แต่ละ Strategy\\nการเรียนรู้ร่วมกันในการปฏิบัติในสถานการณ์จริง PILA\\n(Participatory Interactive Learning through Action)\\n= กระบวนทัศน์ใหม่ในการพัฒนา\\n(New Development Paradigm)\\nเครื่องมือจัดการการแก้ปัญหาที่ยาก\\nชุมชนเข้มแข็ง\\nวัฒนธรรม\\nการศึกษา\\nสังคม\\nสุขภาพ\\nประชาธิปไตย\\nสิ่งแวดล้อม\\nจิตใจ\\nสร้างสัมมาชีพเต็มพื้นที่เป็ นจุดคานงัด\\nเศรษฐกิจ\\nชุมชนเข้มแข็ง\\nวิธีขจัดความยากจนลดความเหลื่อมลํ้า\\n๑. สภาผู้นําชุมชน (องค์กร)\\n๒. สํารวจข้อมูลชุมชน (ความรู้)\\n๓. ทําแผนชุมชน (คิด=เรียนรู้)\\n๔. เสนอสภาประชาชน (ประชาธิปไตยชุมชน)\\n๕. คนทั้งชุมชนปฏิบัติตามแผน (เรียนรู้ร่วมกันในการปฏิบัติ)\\n๖. ติดตามการปฏิบัติแก้อุปสรรคขัดข้อง (การจัดการ)\\n๗. ผลการปฏิบัติและประเมินผลเป็ นข้อมูลป้อนกลับ (การจัดการ)\\n“กระบวนการชุมชน ๗ ขั้นตอน”\\nการขับเคลื่อนระบบโยบายครบวงจร ๑๒ ขั้นตอน\\n= สัมฤทธิศาสตร์\\nI. สังเคราะห์นโยบาย\\n๔  ขั้นตอน\\nII. การตัดสินใจทางการเมือง\\n๑  ขั้นตอน\\nIII. การบริหารจัดการนโยบาย\\n๗  ขั้นตอน \\n= ๑๒ ขั้นตอน \\nนักจัดการทางสังคม\\n“สังคมเข้มแข็ง”\\nประเทศไทยเจริญและสงบสุข\\nเศรษฐกิจดี  การเมืองดี  ศีลธรรมดี\\n'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## example of data input\n",
    "data.iloc[2].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "abe490c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "## all function for use in this task\n",
    "from pythainlp import word_tokenize\n",
    "from pythainlp.tokenize import DEFAULT_DICT_TRIE as trie\n",
    "import docx2txt\n",
    "token_word = docx2txt.process(r'C:\\Users\\ASUS\\Downloads\\คำสำคัญ-10เอกสาร.docx')\n",
    "token_list  = token_word.split(sep = '\\n\\n') \n",
    "trie.add('ประเวศ วะสี')\n",
    "trie.add('สามเหลี่ยมเขยื้อนภูเขา')\n",
    "trie.add('โควิด')\n",
    "for i in token_list:\n",
    "    trie.add(i)\n",
    "import os\n",
    "import pythainlp.tokenize.crfcut as sentences_cut\n",
    "from pythainlp import word_tokenize\n",
    "import re\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "from pythainlp.tag import pos_tag\n",
    "def create_sentences(dict_sent):\n",
    "    dict_sentname = {}\n",
    "    for i in range(len(dict_sent)):\n",
    "        dict_sentname[i+1] = dict_sent[i]['sentence']\n",
    "    dict_pos = {}\n",
    "    for i in range(len(dict_sent)):\n",
    "        dict_pos[i+1] = dict_sent[i]['token_pos']     \n",
    "    Sentences = [dict_sentname,dict_pos]\n",
    "    dict_all = {}\n",
    "    dict_all['sentence_segmentation'] = dict_sentname\n",
    "    dict_all['token_pos'] = dict_pos\n",
    "    return(dict_all)\n",
    "from pythainlp import word_tokenize\n",
    "import re\n",
    "import docx2txt\n",
    "import pandas as pd\n",
    "from pythainlp.tag import pos_tag\n",
    "def list_files(filepath, filetype):\n",
    "    paths = []\n",
    "    filess = []\n",
    "    doc_content = []\n",
    "    for root, dirs, files in os.walk(filepath):\n",
    "        for file in files:\n",
    "            if file.lower().endswith(filetype.lower()):\n",
    "                paths.append(os.path.join(root, file))\n",
    "                filess.append(file)\n",
    "    for file in paths:\n",
    "        doc_content.append(docx2txt.process(file))\n",
    "    f_df = pd.DataFrame(filess)\n",
    "    d_df = pd.DataFrame(doc_content)\n",
    "    all_df = pd.concat([f_df, d_df], axis = 1)\n",
    "    all_df.columns = ['file name','content']\n",
    "    all_df['token + POS'] = all_df['content'].apply(pipeline_pos)\n",
    "    return(all_df)\n",
    "def pipeline_pos(data):\n",
    "        data = data.replace('\\n','')\n",
    "        data = data.replace('\\t','')\n",
    "        data = data.replace('_','')\n",
    "        data = data.replace('“','')\n",
    "        data = data.replace('”','')\n",
    "        word_tokens = []\n",
    "        pos_tag_word = []\n",
    "        list_sentense = sentences_cut.segment(data)\n",
    "        for i in range(len(list_sentense)):\n",
    "            word_tokens.append(word_tokenize(list_sentense[i]))\n",
    "        for i in range(len(word_tokens)):\n",
    "            pos_tag_word.append(pos_tag(word_tokens[i]))\n",
    "        return(pos_tag_word)\n",
    "def clean_df(data):\n",
    "    data = data.replace('\\n','')\n",
    "    data = data.replace('\\t','')\n",
    "    data = data.replace('_','')\n",
    "    data = data.replace('“','')\n",
    "    data = data.replace('”','')\n",
    "    return(data)\n",
    "def to_dict(row):\n",
    "    return {'originalSentence': row['originalSentence'],\n",
    "            'wordPOS': row['wordPOS']}\n",
    "def chage_llt_to_lll(data):\n",
    "    return(list(map(lambda tuple_: [list(t) for t in tuple_], data)))\n",
    "def anirach_transform(data_content,output_name):\n",
    "    test_new = data_content\n",
    "    test_new_clean = clean_df(test_new)\n",
    "    test_sent = sentences_cut.segment(test_new_clean)\n",
    "    word_tokens = []\n",
    "    pos_tag_word = []\n",
    "    for i in range(len(test_sent)):\n",
    "            word_tokens.append(word_tokenize(test_sent[i]))\n",
    "    for i in range(len(word_tokens)):\n",
    "            pos_tag_word.append(pos_tag(word_tokens[i]))\n",
    "    final_json = {'originalSentence':[],'wordPOS':[]}\n",
    "    test_double_list = list(map(lambda tuple_: [list(t) for t in tuple_], pos_tag_word))\n",
    "    for i in range(len(test_sent)):\n",
    "        final_json['originalSentence'].append(test_sent[i])\n",
    "        final_json['wordPOS'].append(test_double_list[i])\n",
    "    df = pd.DataFrame(final_json)\n",
    "    result = df.apply(to_dict, axis=1).tolist()\n",
    "    import json\n",
    "    with open(output_name, \"w\", encoding='utf-8') as outfile:\n",
    "        json.dump(result, outfile,ensure_ascii = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c64486a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "## example to use this code\n",
    "anirach_transform(data.iloc[2].content,'test_again_2.json')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
